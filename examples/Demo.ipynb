{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Hyper-parameter searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Hide info messages from paramiko\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.WARN)\n",
    "\n",
    "import time\n",
    "import random\n",
    "import threading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (2, 2)\n",
    "\n",
    "from distributed import progress, Client\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "from cclyde.cluster import Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Create and launch AWS instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Boto3 and EC2 resources...Done. \n",
      "Ready to configure in preparation to launch cluster! Run: >>> cluster.configure()\n"
     ]
    }
   ],
   "source": [
    "cluster = Cluster(key_name='default_linux', n_nodes=4, cluster_name='default', instance_type='t2.micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking keypair exists using key_name: \"default_linux\"...\n",
      "\tFound pem_key: \"default_linux\"...Done.\n",
      "Checking for Cluster Clyde's Virtual Private Cloud (cclyde_vpc) on AWS...\n",
      "\tFound existing VPC...Done.\n",
      "Checking for Cluster Clyde's Subnet in the VPC...\n",
      "\tFound existing subnet...Done.\n",
      "Validating security group...Found existing cclyde security group, connecting to it...Done.\n",
      "Configuring security group...\n",
      "\tWorking on permission: tcp from port: 22 to port: 22...already exists! Passing.\n",
      "\n",
      "\tWorking on permission: tcp from port: 80 to port: 8786...already exists! Passing.\n",
      "\n",
      "\tWorking on permission: tcp from port: 80 to port: 8787...already exists! Passing.\n",
      "\n",
      "\tWorking on permission: tcp from port: 0 to port: 65535...already exists! Passing.\n",
      "Done configuring security group.\n",
      "Checking for Cluster Clyde's internet gateway...found existing cclyde gateway...Done.\n",
      "Attaching internet gateway to VPC if needed...gateway already associated with VPC...Done.\n",
      "Confirming proper VPC route table configuration...Found existing route table, confirming proper config...Done.\n",
      "Everything is configured, you can now run >>> cluster.launch_instances() OR cluster.reconnect_to_cluster()"
     ]
    }
   ],
   "source": [
    "cluster.configure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:Cluster-Clyde:\tOnce instances are running, you may be accumulating charges from AWS; be sure to run cluster.stop_cluster() *AND* confirm instances are stopped/terminated via AWS console!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All instances in running state, waiting for all to be reachable...\n",
      "All 4 instances ready!\n",
      "Setting node names...Done.\n"
     ]
    }
   ],
   "source": [
    "cluster.launch_instances_nonblocking()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST dataset\n",
    "### Grayscale hand-written digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = load_digits(return_X_y=True)\n",
    "X = np.asarray([x.flatten() for x in X])\n",
    "\n",
    "for i in range(3):\n",
    "    plt.imshow(X[i].reshape((8, 8)), cmap='Greys_r')\n",
    "    plt.title('Digit: {}'.format(y[i]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a NN to predict the numbers (as simple as it gets)\n",
    "## This also demonstrates the time problem of adjusting hyper-parameters\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=30)\n",
    "\n",
    "print 'Features before: ', X.shape[1]\n",
    "\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "print 'Features after: ', X.shape[1]\n",
    "print '{}% Explained Variance'.format(round(sum(pca.explained_variance_ratio_) * 100, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train with some given parameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = MLPClassifier(hidden_layer_sizes=(10, 5), batch_size=10,\n",
    "                   solver='sgd', learning_rate_init=0.01, early_stopping=True)\n",
    "\n",
    "start = time.time()\n",
    "scores = cross_val_score(estimator=lr,\n",
    "                         X=X, \n",
    "                         y=y,\n",
    "                         cv=5)\n",
    "\n",
    "print(\"\\nAccuracy: {}% (+/- {})\".format(round(scores.mean() * 100, 2), round(scores.std(), 3) * 2))\n",
    "print('Finished in {}sec\\n'.format(round(time.time() - start, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Alright, how about something else..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = MLPClassifier(hidden_layer_sizes=(10, 10,), batch_size=100,\n",
    "                   solver='sgd', learning_rate_init=0.01, early_stopping=True)\n",
    "\n",
    "start = time.time()\n",
    "scores = cross_val_score(estimator=lr,\n",
    "                         X=X, \n",
    "                         y=y,\n",
    "                         cv=5)\n",
    "\n",
    "print(\"\\nAccuracy: {}% (+/- {})\".format(round(scores.mean() * 100, 2), round(scores.std(), 3) * 2))\n",
    "print('Finished in {}sec\\n'.format(round(time.time() - start, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and now something different than that.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = MLPClassifier(hidden_layer_sizes=(10, 10, 10,), batch_size=100,\n",
    "                   solver='sgd', learning_rate_init=0.01, early_stopping=True)\n",
    "\n",
    "start = time.time()\n",
    "scores = cross_val_score(estimator=lr,\n",
    "                         X=X, \n",
    "                         y=y,\n",
    "                         cv=5)\n",
    "\n",
    "print(\"\\nAccuracy: {}% (+/- {})\".format(round(scores.mean() * 100, 2), round(scores.std(), 3) * 2))\n",
    "print('Finished in {}sec\\n'.format(round(time.time() - start, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issue: What hyper params are best? \n",
    "\n",
    "Train for all/most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define hyper parameter ranges\n",
    "batch_sizes = np.linspace(start=5, stop=750, num=30, dtype=np.int64)\n",
    "n_layers = range(1, 8, 1)\n",
    "\n",
    "# Make a list of all combinations\n",
    "params = []\n",
    "for batch_size in batch_sizes:\n",
    "    for n_layer in n_layers:\n",
    "\n",
    "        n_neuron = np.random.randint(low=5, high=200)\n",
    "        params.append({'batch_size': batch_size,\n",
    "                       'hidden_layer_sizes': tuple(n_neuron for _ in range(n_layer)),\n",
    "                       'solver': 'sgd',\n",
    "                       'learning_rate_init': 0.01,\n",
    "                       'early_stopping': True\n",
    "                      })\n",
    "\n",
    "print '{} different combinations.'.format(len(params))\n",
    "pprint(params[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This will take a while, even if using all cores on a local machine; let's distribute the workload\n",
    "\n",
    "---\n",
    "\n",
    "Before executing the next few blocks, make sure the instances are ready to connect. If launched with the non-blocking thread, we can check if it's done with `.is_alive()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lauching thread is alive:  False\n"
     ]
    }
   ],
   "source": [
    "print 'Lauching thread is alive: ', cluster.instance_launching_thread.is_alive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing Anaconda on cluster...\n",
      "\n",
      "\n",
      "-------------------\n",
      "\n",
      "Host: 54.172.100.211\tExit Code: 0\n",
      "\n",
      "-------------------\n",
      "\n",
      "Host: 54.158.227.73\tExit Code: 0\n",
      "\n",
      "-------------------\n",
      "\n",
      "Host: 54.87.136.28\tExit Code: 0\n",
      "\n",
      "-------------------\n",
      "\n",
      "Host: 52.90.147.78\tExit Code: 0\n",
      "Done."
     ]
    }
   ],
   "source": [
    "cluster.install_anaconda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Installing package: scikit-learn\n",
      "-------------------\n",
      "\n",
      "Host: 54.172.100.211\tExit Code: 0\n",
      "\n",
      "-------------------\n",
      "\n",
      "Host: 54.158.227.73\tExit Code: 0\n",
      "\n",
      "-------------------\n",
      "\n",
      "Host: 54.87.136.28\tExit Code: 0\n",
      "\n",
      "-------------------\n",
      "\n",
      "Host: 52.90.147.78\tExit Code: 0\n",
      "\n",
      "Installed scikit-learn\n",
      "\n",
      "Installing package: numpy\n",
      "-------------------\n",
      "\n",
      "Host: 54.172.100.211\tExit Code: 0\n",
      "\n",
      "-------------------\n",
      "\n",
      "Host: 54.158.227.73\tExit Code: 0\n",
      "\n",
      "-------------------\n",
      "\n",
      "Host: 54.87.136.28\tExit Code: 0\n",
      "\n",
      "-------------------\n",
      "\n",
      "Host: 52.90.147.78\tExit Code: 0\n",
      "\n",
      "Installed numpy\n",
      "\n",
      "Installing package: pandas\n",
      "-------------------\n",
      "\n",
      "Host: 54.172.100.211\tExit Code: 0\n",
      "\n",
      "-------------------\n",
      "\n",
      "Host: 54.158.227.73\tExit Code: 0\n",
      "\n",
      "-------------------\n",
      "\n",
      "Host: 54.87.136.28\tExit Code: 0\n",
      "\n",
      "-------------------\n",
      "\n",
      "Host: 52.90.147.78\tExit Code: 0\n",
      "\n",
      "Installed pandas\n",
      "\n",
      "Installing package: dask\n",
      "-------------------\n",
      "\n",
      "Host: 54.172.100.211\tExit Code: 0\n",
      "\n",
      "-------------------\n",
      "\n",
      "Host: 54.158.227.73\tExit Code: 0\n",
      "\n",
      "-------------------\n",
      "\n",
      "Host: 54.87.136.28\tExit Code: 0\n",
      "\n",
      "-------------------\n",
      "\n",
      "Host: 52.90.147.78\tExit Code: 0\n",
      "\n",
      "Installed dask\n",
      "\n",
      "Installing package: futures\n",
      "-------------------\n",
      "\n",
      "Host: 54.172.100.211\tExit Code: 0\n",
      "\n",
      "-------------------\n",
      "\n",
      "Host: 54.158.227.73\tExit Code: 0\n",
      "\n",
      "-------------------\n",
      "\n",
      "Host: 54.87.136.28\tExit Code: 0\n",
      "\n",
      "-------------------\n",
      "\n",
      "Host: 52.90.147.78\tExit Code: 0\n",
      "\n",
      "Installed futures\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.install_python_packages(['scikit-learn', 'numpy', 'pandas', 'dask', 'futures'], method='conda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing dask.distributed on cluster\n",
      "\n",
      "-------------------\n",
      "\n",
      "Host: 54.172.100.211\tExit Code: 0\n",
      "\n",
      "-------------------\n",
      "\n",
      "Host: 54.158.227.73\tExit Code: 0\n",
      "\n",
      "-------------------\n",
      "\n",
      "Host: 54.87.136.28\tExit Code: 0\n",
      "\n",
      "-------------------\n",
      "\n",
      "Host: 52.90.147.78\tExit Code: 0\n",
      "\n",
      "Launching scheduler on master node...\n",
      "-------------------\n",
      "\n",
      "Host: 52.90.147.78\tExit Code: 0\n",
      "\tSTDOUT for 52.90.147.78:\n",
      "\t\t()Done.\n",
      "\n",
      "Launching workers...\n",
      "-------------------\n",
      "\n",
      "Host: 54.172.100.211\tExit Code: 0\n",
      "\tSTDOUT for 54.172.100.211:\n",
      "\t\t()\n",
      "-------------------\n",
      "\n",
      "Host: 54.158.227.73\tExit Code: 0\n",
      "\tSTDOUT for 54.158.227.73:\n",
      "\t\t()\n",
      "-------------------\n",
      "\n",
      "Host: 54.87.136.28\tExit Code: 0\n",
      "\tSTDOUT for 54.87.136.28:\n",
      "\t\t()Done.\n",
      "\n",
      "Scheduler should be available here: 52.90.147.78:8786\n",
      "Web Dashboard should be available here: 52.90.147.78:8787"
     ]
    }
   ],
   "source": [
    "cluster.launch_dask()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the resulting scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Client: scheduler=\"52.90.147.78:8786\" processes=3 cores=3>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Client(address='52.90.147.78:8786')\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Define functions which will be distributed to workers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(kwargs):\n",
    "    \"\"\"\n",
    "    Function which gets data and performs PCA on it.\n",
    "    \"\"\"\n",
    "    from sklearn.datasets import load_digits\n",
    "    from sklearn.decomposition import PCA\n",
    "    import numpy as np\n",
    "    \n",
    "    X, y = load_digits(return_X_y=True)\n",
    "    X = np.asarray([x.flatten() for x in X])\n",
    "    pca = PCA(n_components=30)\n",
    "    X = pca.fit_transform(X)\n",
    "    \n",
    "    return (kwargs, X, y)\n",
    "\n",
    "\n",
    "def model_tester(package):\n",
    "    \"\"\"\n",
    "    Function which is mapped to cluster. Passes kwargs to model to be trained.\n",
    "    Returns score based on those kwargs.\n",
    "    \"\"\"\n",
    "    \n",
    "    kwargs, X, y = package\n",
    "    \n",
    "    import time\n",
    "    import numpy as np\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    \n",
    "    # Initialize model with given kwargs\n",
    "    lr = MLPClassifier(**kwargs)\n",
    "    scores = cross_val_score(estimator=lr,\n",
    "                             X=X, \n",
    "                             y=y,\n",
    "                             cv=5)\n",
    "    return (kwargs, scores.mean(), scores.std())\n",
    "\n",
    "\n",
    "def score_combiner(package):\n",
    "    \"\"\"\n",
    "    Not needed, but more functions == more pretty colors\n",
    "    \"\"\"\n",
    "    import time\n",
    "    import random\n",
    "    time.sleep(random.random())\n",
    "    \n",
    "    kwargs, score_m, score_std = package\n",
    "    kwargs.update({'score': score_m, 'std': score_std})\n",
    "    \n",
    "    return kwargs\n",
    "\n",
    "\n",
    "def double(n):\n",
    "    '''\n",
    "    Useless worker function # 1\n",
    "    '''\n",
    "    import time\n",
    "    import random\n",
    "    import sklearn\n",
    "    time.sleep(random.random())\n",
    "    return n * 2, 2\n",
    "\n",
    "\n",
    "def add_two(package):\n",
    "    \"\"\"\n",
    "    Useless worker function # 2\n",
    "    \"\"\"\n",
    "    n, n2 = package\n",
    "    import time\n",
    "    import random\n",
    "    time.sleep(random.random())\n",
    "    return n + n2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test out some test functions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed properly. Did you enable the widgetsnbextension? If not, then run \"jupyter nbextension enable --py --sys-prefix widgetsnbextension\"\n"
     ]
    }
   ],
   "source": [
    "futures = c.map(double, range(250))\n",
    "futures = c.map(add_two, futures)\n",
    "progress(futures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribute the actual work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "futures = c.map(get_data, params)\n",
    "futures = c.map(model_tester, futures)\n",
    "futures = c.map(score_combiner, futures)\n",
    "progress(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c.gather(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = c.gather(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df['n_layers'] = df.hidden_layer_sizes.map(lambda _tuple: len(_tuple)) \n",
    "df['n_neurons'] = df.hidden_layer_sizes.map(lambda _tuple: _tuple[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.n_layers.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "data = []\n",
    "for n_layers in df.n_layers.unique():\n",
    "    \n",
    "    temp = df[df.n_layers == n_layers]\n",
    "    \n",
    "    trace = go.Scatter(\n",
    "        x = temp.n_neurons,\n",
    "        y = temp.n_layers,\n",
    "        mode='markers',\n",
    "        text=['{}%<br>Layers: {}'.format(round(v * 100, 2), l) \n",
    "              for v, l in zip(temp.score.values, temp.n_layers.values)],\n",
    "        name='{} layers'.format(n_layers),\n",
    "        marker=dict(\n",
    "            size=temp.batch_size / 20.0,\n",
    "            color = temp.score, #set color equal to a variable\n",
    "            colorscale='Viridis',\n",
    "            showscale=False\n",
    "        )\n",
    "    )\n",
    "    data.append(trace)\n",
    "\n",
    "layout = dict(title = 'Best performing models.<br>(size = batch size)',\n",
    "              xaxis = dict(zeroline = False, title='Neuron Count'),\n",
    "              yaxis = dict(zeroline = False, title='Layer Count'),\n",
    "             )\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename='styled-scatter')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.ix[df.score.argmax(), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Also create a distributed queue system..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Queue import Queue\n",
    "local_q = Queue()\n",
    "remote_q = c.scatter(local_q)\n",
    "\n",
    "def long_calc1(n):\n",
    "    \n",
    "    import time\n",
    "    import random\n",
    "    \n",
    "    time.sleep(random.random())\n",
    "    \n",
    "    return n + 2\n",
    "\n",
    "def long_calc2(n):\n",
    "    \n",
    "    import time\n",
    "    import random\n",
    "    \n",
    "    time.sleep(random.random())\n",
    "    \n",
    "    return n * 2\n",
    "\n",
    "def long_calc3(n):\n",
    "    \n",
    "    import time\n",
    "    import random\n",
    "    \n",
    "    time.sleep(random.random())\n",
    "    \n",
    "    return n - 2\n",
    "\n",
    "\n",
    "long_calc1_q = c.map(long_calc1, remote_q)\n",
    "long_calc2_q = c.map(long_calc2, long_calc1_q)\n",
    "long_calc3_q = c.map(long_calc3, long_calc2_q)\n",
    "result_q = c.gather(long_calc3_q)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## queue is currently empty..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_q.qsize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start submitting jobs to the queue with a thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def start_jobs():\n",
    "\n",
    "    jobs = range(500)\n",
    "\n",
    "    for job in jobs:\n",
    "        time.sleep(random.random())\n",
    "        local_q.put(job)\n",
    "        \n",
    "    return \n",
    "\n",
    "thread = threading.Thread(target=start_jobs)\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## and begin receiving the results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_jobs():\n",
    "    while True:\n",
    "        print result_q.get()\n",
    "        \n",
    "    return\n",
    "\n",
    "finish_thread = threading.Thread(target=get_jobs)\n",
    "finish_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:Cluster-Clyde:Terminated instances. Please check your AWS console to ensure termination of nodes!\n"
     ]
    }
   ],
   "source": [
    "cluster.terminate_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:testenv]",
   "language": "python",
   "name": "conda-env-testenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {
    "d802e3f6203a4ee7892ee9fd006c3524": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Hyper-parameter searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import random\n",
    "import threading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (2, 2)\n",
    "\n",
    "from distributed import progress, Client\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "from cclyde.cluster import Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Create and launch AWS instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cluster = Cluster(key_name='default_linux', n_nodes=2, cluster_name='default', instance_type='t2.micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cluster.configure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cluster.launch_instances_nonblocking()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST dataset\n",
    "### Grayscale hand-written digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = load_digits(return_X_y=True)\n",
    "X = np.asarray([x.flatten() for x in X])\n",
    "\n",
    "for i in range(3):\n",
    "    plt.imshow(X[i].reshape((8, 8)), cmap='Greys_r')\n",
    "    plt.title('Digit: {}'.format(y[i]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a NN to predict the numbers (as simple as it gets)\n",
    "## This also demonstrates the time problem of adjusting hyper-parameters\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=20)\n",
    "\n",
    "print 'Features before: ', X.shape[1]\n",
    "\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "print 'Features after: ', X.shape[1]\n",
    "print '{}% Explained Variance'.format(round(sum(pca.explained_variance_ratio_) * 100, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train with some given parameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = MLPClassifier(hidden_layer_sizes=(10, 5), batch_size=10,\n",
    "                   solver='sgd', learning_rate_init=0.01, early_stopping=True)\n",
    "\n",
    "start = time.time()\n",
    "scores = cross_val_score(estimator=lr,\n",
    "                         X=X, \n",
    "                         y=y,\n",
    "                         cv=5)\n",
    "\n",
    "print(\"\\nAccuracy: {}% (+/- {})\".format(round(scores.mean() * 100, 2), round(scores.std(), 3) * 2))\n",
    "print('Finished in {}sec\\n'.format(round(time.time() - start, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Alright, how about something else..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = MLPClassifier(hidden_layer_sizes=(10, 10,), batch_size=100,\n",
    "                   solver='sgd', learning_rate_init=0.01, early_stopping=True)\n",
    "\n",
    "start = time.time()\n",
    "scores = cross_val_score(estimator=lr,\n",
    "                         X=X, \n",
    "                         y=y,\n",
    "                         cv=5)\n",
    "\n",
    "print(\"\\nAccuracy: {}% (+/- {})\".format(round(scores.mean() * 100, 2), round(scores.std(), 3) * 2))\n",
    "print('Finished in {}sec\\n'.format(round(time.time() - start, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and now something different than that.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = MLPClassifier(hidden_layer_sizes=(10, 10, 10,), batch_size=100,\n",
    "                   solver='sgd', learning_rate_init=0.01, early_stopping=True)\n",
    "\n",
    "start = time.time()\n",
    "scores = cross_val_score(estimator=lr,\n",
    "                         X=X, \n",
    "                         y=y,\n",
    "                         cv=5)\n",
    "\n",
    "print(\"\\nAccuracy: {}% (+/- {})\".format(round(scores.mean() * 100, 2), round(scores.std(), 3) * 2))\n",
    "print('Finished in {}sec\\n'.format(round(time.time() - start, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issue: What hyper params are best? \n",
    "\n",
    "Train for all/most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define hyper parameter ranges\n",
    "batch_sizes = np.linspace(start=5, stop=750, num=30, dtype=np.int64)\n",
    "n_layers = range(1, 8, 1)\n",
    "\n",
    "# Make a list of all combinations\n",
    "params = []\n",
    "for batch_size in batch_sizes:\n",
    "    for n_layer in n_layers:\n",
    "\n",
    "        n_neuron = np.random.randint(low=5, high=200)\n",
    "        params.append({'batch_size': batch_size,\n",
    "                       'hidden_layer_sizes': tuple(n_neuron for _ in range(n_layer)),\n",
    "                       'solver': 'sgd',\n",
    "                       'learning_rate_init': 0.01,\n",
    "                       'early_stopping': True\n",
    "                      })\n",
    "\n",
    "print '{} different combinations.'.format(len(params))\n",
    "pprint(params[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This will take a while, even if using all cores on a local machine; let's distribute the workload\n",
    "\n",
    "---\n",
    "\n",
    "Before executing the next few blocks, make sure the instances are ready to connect. If launched with the non-blocking thread, we can check if it's done with `.is_alive()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Lauching thread is alive: ', cluster.instance_launching_thread.is_alive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster.install_anaconda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster.install_python_packages(['scikit-learn', 'numpy', 'pandas', 'dask', 'futures'], method='conda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster.launch_dask()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the resulting scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = Client(address='<address from master node>:8786')\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Define functions which will be distributed to workers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(kwargs):\n",
    "    \"\"\"\n",
    "    Function which gets data and performs PCA on it.\n",
    "    \"\"\"\n",
    "    from sklearn.datasets import load_digits\n",
    "    from sklearn.decomposition import PCA\n",
    "    import numpy as np\n",
    "    \n",
    "    X, y = load_digits(return_X_y=True)\n",
    "    X = np.asarray([x.flatten() for x in X])\n",
    "    pca = PCA(n_components=20)\n",
    "    X = pca.fit_transform(X)\n",
    "    \n",
    "    return (kwargs, X, y)\n",
    "\n",
    "\n",
    "def model_tester(package):\n",
    "    \"\"\"\n",
    "    Function which is mapped to cluster. Passes kwargs to model to be trained.\n",
    "    Returns score based on those kwargs.\n",
    "    \"\"\"\n",
    "    \n",
    "    kwargs, X, y = package\n",
    "    \n",
    "    import time\n",
    "    import numpy as np\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    \n",
    "    # Initialize model with given kwargs\n",
    "    lr = MLPClassifier(**kwargs)\n",
    "    scores = cross_val_score(estimator=lr,\n",
    "                             X=X, \n",
    "                             y=y,\n",
    "                             cv=5)\n",
    "    return (kwargs, scores.mean(), scores.std())\n",
    "\n",
    "\n",
    "def score_combiner(package):\n",
    "    \"\"\"\n",
    "    Not needed, but more functions == more pretty colors\n",
    "    \"\"\"\n",
    "    import time\n",
    "    import random\n",
    "    time.sleep(random.random())\n",
    "    \n",
    "    kwargs, score_m, score_std = package\n",
    "    kwargs.update({'score': score_m, 'std': score_std})\n",
    "    \n",
    "    return kwargs\n",
    "\n",
    "\n",
    "def double(n):\n",
    "    '''\n",
    "    Useless worker function # 1\n",
    "    '''\n",
    "    import time\n",
    "    import random\n",
    "    import sklearn\n",
    "    time.sleep(random.random())\n",
    "    return n * 2, 2\n",
    "\n",
    "\n",
    "def add_two(package):\n",
    "    \"\"\"\n",
    "    Useless worker function # 2\n",
    "    \"\"\"\n",
    "    n, n2 = package\n",
    "    import time\n",
    "    import random\n",
    "    time.sleep(random.random())\n",
    "    return n + n2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test out some test functions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "futures = c.map(double, range(5))\n",
    "futures = c.map(add_two, futures)\n",
    "progress(futures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribute the actual work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "futures = c.map(get_data, params)\n",
    "futures = c.map(model_tester, futures)\n",
    "futures = c.map(score_combiner, futures)\n",
    "progress(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c.gather(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = c.gather(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df['n_layers'] = df.hidden_layer_sizes.map(lambda _tuple: len(_tuple)) \n",
    "df['n_neurons'] = df.hidden_layer_sizes.map(lambda _tuple: _tuple[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.n_layers.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "data = []\n",
    "for n_layers in df.n_layers.unique():\n",
    "    \n",
    "    temp = df[df.n_layers == n_layers]\n",
    "    \n",
    "    trace = go.Scatter(\n",
    "        x = temp.n_neurons,\n",
    "        y = temp.n_layers,\n",
    "        mode='markers',\n",
    "        text=['{}%<br>Layers: {}'.format(round(v * 100, 2), l) \n",
    "              for v, l in zip(temp.score.values, temp.n_layers.values)],\n",
    "        name='{} layers'.format(n_layers),\n",
    "        marker=dict(\n",
    "            size=temp.batch_size / 20.0,\n",
    "            color = temp.score, #set color equal to a variable\n",
    "            colorscale='Viridis',\n",
    "            showscale=False\n",
    "        )\n",
    "    )\n",
    "    data.append(trace)\n",
    "\n",
    "layout = dict(title = 'Best performing models.<br>(size = batch size)',\n",
    "              xaxis = dict(zeroline = False, title='Neuron Count'),\n",
    "              yaxis = dict(zeroline = False, title='Layer Count'),\n",
    "             )\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename='styled-scatter')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.ix[df.score.argmax(), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Also create a distributed queue system..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Queue import Queue\n",
    "local_q = Queue()\n",
    "remote_q = c.scatter(local_q)\n",
    "\n",
    "def long_calc1(n):\n",
    "    \n",
    "    import time\n",
    "    import random\n",
    "    \n",
    "    time.sleep(random.random())\n",
    "    \n",
    "    return n + 2\n",
    "\n",
    "def long_calc2(n):\n",
    "    \n",
    "    import time\n",
    "    import random\n",
    "    \n",
    "    time.sleep(random.random())\n",
    "    \n",
    "    return n * 2\n",
    "\n",
    "def long_calc3(n):\n",
    "    \n",
    "    import time\n",
    "    import random\n",
    "    \n",
    "    time.sleep(random.random())\n",
    "    \n",
    "    return n - 2\n",
    "\n",
    "\n",
    "long_calc1_q = c.map(long_calc1, remote_q)\n",
    "long_calc2_q = c.map(long_calc2, long_calc1_q)\n",
    "long_calc3_q = c.map(long_calc3, long_calc2_q)\n",
    "result_q = c.gather(long_calc3_q)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## queue is currently empty..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_q.qsize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start submitting jobs to the queue with a thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def start_jobs():\n",
    "\n",
    "    jobs = range(500)\n",
    "\n",
    "    for job in jobs:\n",
    "        time.sleep(random.random())\n",
    "        local_q.put(job)\n",
    "        \n",
    "    return \n",
    "\n",
    "thread = threading.Thread(target=start_jobs)\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## and begin receiving the results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_jobs():\n",
    "    while True:\n",
    "        print result_q.get()\n",
    "        \n",
    "    return\n",
    "\n",
    "finish_thread = threading.Thread(target=get_jobs)\n",
    "finish_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cluster.terminate_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Cluster Clyde - Python 2.7",
   "language": "python",
   "name": "clusterclyde"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
